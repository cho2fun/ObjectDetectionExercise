{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1667  514   27   27]\n",
      " [ 886  123   31   31]\n",
      " [ 412  126   37   37]\n",
      " [ 992  139   38   38]\n",
      " [1560  275   32   32]\n",
      " [1364    9   61   61]\n",
      " [ 808  129   65   65]\n",
      " [ 866  133   53   53]\n",
      " [ 928  131   64   64]\n",
      " [ 573    5   65   65]\n",
      " [ 515  253   65   65]\n",
      " [1561  685   61   61]\n",
      " [1208   15   54   54]\n",
      " [ 623  109  101  101]\n",
      " [1770   29   62   62]\n",
      " [ 524  295   50   50]\n",
      " [ 544   77   58   58]\n",
      " [1626   65   61   61]\n",
      " [ 433   71   60   60]\n",
      " [  90   74   72   72]\n",
      " [ 642  442   81   81]\n",
      " [ 660  152   63   63]\n",
      " [1189  150   59   59]\n",
      " [ 919   71   74   74]\n",
      " [1032  160   68   68]\n",
      " [1363   32   64   64]\n",
      " [1304   98   57   57]\n",
      " [1438   86   68   68]\n",
      " [ 581  162   56   56]\n",
      " [1802   97   64   64]\n",
      " [1585  624   67   67]\n",
      " [ 656  105   45   45]\n",
      " [ 715   99   52   52]\n",
      " [1569  478  100  100]]\n",
      "(34, 4)\n",
      "number of faces detected :[1667  514   27   27]\n",
      "image shape (900, 1920, 3)\n",
      "image shape[0] 900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('d:/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "# lena.png\n",
    "fileName = 'd:/opencv/images/loreal.jpg'\n",
    "image = cv2.imread(fileName, cv2.COLOR_BGR2GRAY) #cv2.IMREAD_COLOR)\n",
    "np_image = np.copy(image)\n",
    "gray_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_image)\n",
    "print(type(faces))\n",
    "print(faces)\n",
    "print(faces.shape)\n",
    "print('number of faces detected :' + str(faces[0]))\n",
    "print('image shape ' + str(image.shape))\n",
    "print('image shape[0] ' + str(image.shape[0]))\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "cv2.rectangle(image, ((0,image.shape[0] -25)),(270, image.shape[0]), (0,255,255), -1)\n",
    "cv2.putText(image, \"Number of faces detected: \" + str(faces.shape[0]), (0,image.shape[0] -500), cv2.FONT_HERSHEY_TRIPLEX, .75, (0,255,0), 1)\n",
    "cv2.imshow('original face', image)\n",
    "#cv2.imshow('grey face', gray_image) \n",
    "#cv2.imshow('result ', faces)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
